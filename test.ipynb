{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "sys.path.append('core')\n",
    "\n",
    "import argparse, configparser\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.optim import Adam as AdamW\n",
    "from torch.optim.adamw import AdamW\n",
    "from core.onecyclelr import OneCycleLR\n",
    "\n",
    "from tensorboardX import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.cuda.amp import GradScaler\n",
    "except:\n",
    "    # dummy GradScaler for PyTorch < 1.6\n",
    "    class GradScaler:\n",
    "        def __init__(self, enabled=False):\n",
    "            pass\n",
    "        def scale(self, loss):\n",
    "            return loss\n",
    "        def unscale_(self, optimizer):\n",
    "            pass\n",
    "        def step(self, optimizer):\n",
    "            optimizer.step()\n",
    "        def update(self):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from glob import glob\n",
    "import os.path as osp\n",
    "\n",
    "from utils import frame_utils\n",
    "from utils.augmentor import FlowAugmentor, SparseFlowAugmentor\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, aug_params=None, sparse=False):\n",
    "        self.augmentor = None\n",
    "        self.sparse = sparse\n",
    "        if aug_params is not None:\n",
    "            if sparse:\n",
    "                self.augmentor = SparseFlowAugmentor(**aug_params)\n",
    "            else:\n",
    "                self.augmentor = FlowAugmentor(**aug_params)\n",
    "\n",
    "        self.is_test = False\n",
    "        self.is_validate = False\n",
    "        self.init_seed = False\n",
    "        self.flow_list = []\n",
    "        self.image_list = []\n",
    "        self.extra_info = []\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print('Index is {}'.format(index))\n",
    "        # sys.stdout.flush()\n",
    "        if self.is_test:\n",
    "            img1 = frame_utils.read_gen(self.image_list[index][0])\n",
    "            img2 = frame_utils.read_gen(self.image_list[index][1])\n",
    "            img1 = np.array(img1).astype(np.uint8)[..., :3]\n",
    "            img2 = np.array(img2).astype(np.uint8)[..., :3]\n",
    "            img1 = torch.from_numpy(img1).permute(2, 0, 1).float()\n",
    "            img2 = torch.from_numpy(img2).permute(2, 0, 1).float()\n",
    "            return img1, img2, self.extra_info[index]\n",
    "\n",
    "        # if not self.init_seed:\n",
    "        #     worker_info = torch.utils.data.get_worker_info()\n",
    "        #     if worker_info is not None:\n",
    "        #         torch.manual_seed(worker_info.id)\n",
    "        #         np.random.seed(worker_info.id)\n",
    "        #         random.seed(worker_info.id)\n",
    "        #         self.init_seed = True\n",
    "\n",
    "        index = index % len(self.image_list)\n",
    "        valid = None\n",
    "        h,w = 600,800\n",
    "        if self.sparse:\n",
    "            flow, valid = frame_utils.readFlowKITTI(self.flow_list[index])\n",
    "        else:\n",
    "            flow = frame_utils.read_gen(self.flow_list[index],h = h,w = w)\n",
    "\n",
    "        img1 = frame_utils.read_gen(self.image_list[index][0])\n",
    "        img2 = frame_utils.read_gen(self.image_list[index][1])\n",
    "\n",
    "        flow = np.array(flow).astype(np.float32)\n",
    "        img1 = np.array(img1).astype(np.uint8)\n",
    "        img2 = np.array(img2).astype(np.uint8)\n",
    "\n",
    "        # grayscale images\n",
    "        if len(img1.shape) == 2:\n",
    "            img1 = np.tile(img1[...,None], (1, 1, 3))\n",
    "            img2 = np.tile(img2[...,None], (1, 1, 3))\n",
    "        else:\n",
    "            img1 = img1[..., :3]\n",
    "            img2 = img2[..., :3]\n",
    "\n",
    "        if self.augmentor is not None:\n",
    "            if self.sparse:\n",
    "                img1, img2, flow, valid = self.augmentor(img1, img2, flow, valid)\n",
    "            else:\n",
    "                img1, img2, flow = self.augmentor(img1, img2, flow)\n",
    "\n",
    "        img1 = torch.from_numpy(img1).permute(2, 0, 1).float()\n",
    "        img2 = torch.from_numpy(img2).permute(2, 0, 1).float()\n",
    "        flow = torch.from_numpy(flow).permute(2, 0, 1).float()\n",
    "\n",
    "        if valid is not None:\n",
    "            valid = torch.from_numpy(valid)\n",
    "        else:\n",
    "            valid = (flow[0].abs() < 1000) & (flow[1].abs() < 1000)\n",
    "\n",
    "        if self.is_validate:\n",
    "            return img1, img2, flow, valid.float(), self.extra_info[index]\n",
    "        else:\n",
    "            return img1, img2, flow, valid.float()\n",
    "\n",
    "    def getDataWithPath(self, index):\n",
    "        img1, img2, flow, valid = self.__getitem__(index)\n",
    "\n",
    "        imgPath_1 = self.image_list[index][0]\n",
    "        imgPath_2 = self.image_list[index][1]\n",
    "\n",
    "        return img1, img2, flow, valid, imgPath_1, imgPath_2\n",
    "\n",
    "    def __rmul__(self, v):\n",
    "        self.flow_list = v * self.flow_list\n",
    "        self.image_list = v * self.image_list\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Carla_Dataset(FlowDataset):\n",
    "    def __init__(self, aug_params=None, split='training', root='/home/sushlok/new_approach/datasets/carla', \n",
    "                 seq= [\n",
    "                    \"SoftRainNight\",\n",
    "                    \"ClearNoon\",\n",
    "                    \"CloudyNoon\"\n",
    "                ], \n",
    "            setup_type = [ 'camera_0', 'camera_-1','camera_1'], is_validate=False):\n",
    "        super(Carla_Dataset, self).__init__(aug_params, sparse=False)\n",
    "        if split == 'testing':\n",
    "            self.is_test = True\n",
    "\n",
    "        self.is_validate = is_validate\n",
    "        image_dirs = []\n",
    "        # datasets/vkitti/vkitti_1.3.1_rgb\n",
    "        # print(seq, setup_type)\n",
    "        start = 0\n",
    "        for s in seq:\n",
    "            for t in setup_type:\n",
    "                # print(sorted(glob(osp.join(root, '%s' %(s) ,'rgb_%s/*.png' % (t)))))\n",
    "                image_dirs += sorted(glob(osp.join(root, '%s' %(s) ,'rgb_%s/*.png' % (t))))\n",
    "                # print(image_dirs)\n",
    "                for i in range(start,len(image_dirs)-1):\n",
    "                    img1 = image_dirs[i]\n",
    "                    img2 = image_dirs[i+1]  \n",
    "                    self.image_list += [ [img2, img1] ]\n",
    "                    self.extra_info += [ [img2.split('/')[-1]] ]\n",
    "                start = len(image_dirs)\n",
    "            \n",
    "        if split == 'training':\n",
    "            for s in seq:\n",
    "                for t in setup_type:\n",
    "                    self.flow_list += sorted(glob(osp.join(root, '%s' %(s) ,'flow_%s/flow_npz/*.npz' % (t))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only using crop FlowAugmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using_flowaugmentor\n"
     ]
    }
   ],
   "source": [
    "aug_params = {'crop_size': [320, 480], 'min_scale': -0.2, 'max_scale': 0.4, 'do_flip': False}\n",
    "train_dataset = Carla_Dataset(aug_params, split='training', seq= [\"ClearNoon\"], setup_type = [\"camera_0\",\"camera_-1\",\"camera_1\",\"camera_-10\",\"camera_10\",\"camera_-11\",\"camera_11\",\"camera_12\",\"camera_-2\",\"camera_2\",\"camera_-3\",\"camera_3\",\"camera_-4\",\"camera_4\",\"camera_-5\",\"camera_5\",\"camera_-6\",\"camera_6\",\"camera_-7\",\"camera_7\",\"camera_-8\",\"camera_8\",\"camera_-9\",\"camera_9\"])\n",
    "# validation_datset = Carla_Dataset(aug_params, split='training', seq= [\"CloudyNoon\"], setup_type = [\"camera_0\"])\n",
    "# valid_loader = torch.utils.data.DataLoader(validation_datset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True, drop_last=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "from core.update import BasicUpdateBlock\n",
    "from core.extractor import BasicEncoder, BasicConvEncoder, Non_uniform_Encoder\n",
    "from core.corr import CorrBlock, AlternateCorrBlock\n",
    "from utils.utils import bilinear_sampler, coords_grid, upflow8\n",
    "from core.swin_transformer import POLAUpdate, MixAxialPOLAUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocast = torch.cuda.amp.autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMFlowNetModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.hidden_dim = hdim = 128\n",
    "        self.context_dim = cdim = 128\n",
    "        args.corr_levels = 4\n",
    "        args.corr_radius = 4\n",
    "        args.dropout = 0.0\n",
    "        args.use_mix_attn = False\n",
    "        args.mixed_precision = True\n",
    "        if not hasattr(self.args, 'dropout'):\n",
    "            self.args.dropout = 0\n",
    "\n",
    "        if not hasattr(self.args, 'alternate_corr'):\n",
    "            self.args.alternate_corr = False\n",
    "\n",
    "        # feature network, context network, and update block\n",
    "        if self.args.use_mix_attn:\n",
    "            self.fnet = nn.Sequential(\n",
    "                            BasicConvEncoder(output_dim=256, norm_fn='instance', dropout=args.dropout),\n",
    "                            # Non_uniform_Encoder(output_dim=256, norm_fn='instance', dropout=args.dropout),\n",
    "                            MixAxialPOLAUpdate(embed_dim=256, depth=6, num_head=8, window_size=7)\n",
    "                        )\n",
    "        else:\n",
    "            self.fnet = nn.Sequential(\n",
    "                # Non_uniform_Encoder(output_dim=256, norm_fn='instance', dropout=args.dropout),\n",
    "                BasicConvEncoder(output_dim=256, norm_fn='instance', dropout=args.dropout),\n",
    "                POLAUpdate(embed_dim=256, depth=6, num_head=8, window_size=7, neig_win_num=1)\n",
    "            )\n",
    "\n",
    "        self.cnet = BasicEncoder(output_dim=hdim+cdim, norm_fn='batch', dropout=args.dropout)\n",
    "        self.update_block = BasicUpdateBlock(self.args, hidden_dim=hdim, input_dim=cdim)\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def initialize_flow(self, img):\n",
    "        \"\"\" Flow is represented as difference between two coordinate grids flow = coords1 - coords0\"\"\"\n",
    "        N, C, H, W = img.shape\n",
    "        coords0 = coords_grid(N, H//8, W//8).to(img.device)\n",
    "        coords1 = coords_grid(N, H//8, W//8).to(img.device)\n",
    "\n",
    "        # optical flow computed as difference: flow = coords1 - coords0\n",
    "        return coords0, coords1\n",
    "\n",
    "    def upsample_flow(self, flow, mask):\n",
    "        \"\"\" Upsample flow field [H/8, W/8, 2] -> [H, W, 2] using convex combination \"\"\"\n",
    "        N, _, H, W = flow.shape\n",
    "        mask = mask.view(N, 1, 9, 8, 8, H, W)\n",
    "        mask = torch.softmax(mask, dim=2)\n",
    "\n",
    "        up_flow = F.unfold(8 * flow, [3,3], padding=1)\n",
    "        up_flow = up_flow.view(N, 2, 9, 1, 1, H, W)\n",
    "\n",
    "        up_flow = torch.sum(mask * up_flow, dim=2)\n",
    "        up_flow = up_flow.permute(0, 1, 4, 2, 5, 3)\n",
    "        return up_flow.reshape(N, 2, 8*H, 8*W)\n",
    "\n",
    "    def forward(self, image1, image2, iters=12, flow_init=None, upsample=True, test_mode=False):\n",
    "        \"\"\" Estimate optical flow between pair of frames \"\"\"\n",
    "\n",
    "        image1 = 2 * (image1 / 255.0) - 1.0\n",
    "        image2 = 2 * (image2 / 255.0) - 1.0\n",
    "\n",
    "        image1 = image1.contiguous()\n",
    "        image2 = image2.contiguous()\n",
    "\n",
    "        hdim = self.hidden_dim\n",
    "        cdim = self.context_dim\n",
    "\n",
    "        # run the feature network\n",
    "        with autocast(enabled=self.args.mixed_precision):\n",
    "            fmaps, cache = self.fnet([image1, image2])\n",
    "        fmap1,fmap2 = fmaps\n",
    "        fmap1 = fmap1.float()\n",
    "        fmap2 = fmap2.float()\n",
    "\n",
    "        # # Self-attention update\n",
    "        # fmap1 = self.transEncoder(fmap1)\n",
    "        # fmap2 = self.transEncoder(fmap2)\n",
    "        # print(\"feature_volume:\")\n",
    "        # # print(fmap1, fmap2)\n",
    "        # print(fmap1.shape)\n",
    "        # print(\"------------------------------------------------\")\n",
    "        if self.args.alternate_corr:\n",
    "            corr_fn = AlternateCorrBlock(fmap1, fmap2, radius=self.args.corr_radius)\n",
    "        else:\n",
    "            corr_fn = CorrBlock(fmap1, fmap2, radius=self.args.corr_radius)\n",
    "\n",
    "        # print(\"corr_fn:\")\n",
    "        # # print(corr_fn.corrMap)\n",
    "        # print(\"------------------------------------------------\")\n",
    "        # print(corr_fn.corrMap.shape)\n",
    "        # run the context network\n",
    "        with autocast(enabled=self.args.mixed_precision):\n",
    "            cnet = self.cnet(image1)\n",
    "            net, inp = torch.split(cnet, [hdim, cdim], dim=1)\n",
    "            net = torch.tanh(net)\n",
    "            inp = torch.relu(inp)\n",
    "\n",
    "        coords0, coords1 = self.initialize_flow(image1)\n",
    "\n",
    "        # Correlation as initialization\n",
    "        N, fC, fH, fW = fmap1.shape\n",
    "        corrMap = corr_fn.corrMap\n",
    "\n",
    "        #_, coords_index = torch.max(corrMap, dim=-1) # no gradient here\n",
    "        softCorrMap = F.softmax(corrMap, dim=2) * F.softmax(corrMap, dim=1) # (N, fH*fW, fH*fW)\n",
    "\n",
    "        # print(\"softCorrMap:\")\n",
    "        # # print(softCorrMap)\n",
    "        # print(\"------------------------------------------------\")\n",
    "        # print(softCorrMap.shape)\n",
    "        if flow_init is not None:\n",
    "            coords1 = coords1 + flow_init\n",
    "        else:\n",
    "            # print('matching as init')\n",
    "            # mutual match selection\n",
    "            match12, match_idx12 = softCorrMap.max(dim=2) # (N, fH*fW)\n",
    "            match21, match_idx21 = softCorrMap.max(dim=1)\n",
    "\n",
    "            for b_idx in range(N):\n",
    "                match21_b = match21[b_idx,:]\n",
    "                match_idx12_b = match_idx12[b_idx,:]\n",
    "                match21[b_idx,:] = match21_b[match_idx12_b]\n",
    "\n",
    "            matched = (match12 - match21) == 0  # (N, fH*fW)\n",
    "            coords_index = torch.arange(fH*fW).unsqueeze(0).repeat(N,1).to(softCorrMap.device)\n",
    "            coords_index[matched] = match_idx12[matched]\n",
    "\n",
    "            # matched coords\n",
    "            coords_index = coords_index.reshape(N, fH, fW)\n",
    "            coords_x = coords_index % fW\n",
    "            coords_y = coords_index // fW\n",
    "\n",
    "            coords_xy = torch.stack([coords_x, coords_y], dim=1).float()\n",
    "            coords1 = coords_xy\n",
    "        # print('coords1:')\n",
    "        # # print(coords1)\n",
    "        # print(coords1.shape)\n",
    "        # print(\"------------------------------------------------\")\n",
    "        \n",
    "        # Iterative update\n",
    "        flow_predictions = []\n",
    "        # print(\"iter:\",iter)\n",
    "        for itr in range(iters):\n",
    "            # print(itr)\n",
    "            coords1 = coords1.detach()\n",
    "            corr = corr_fn(coords1) # index correlation volume\n",
    "\n",
    "            flow = coords1 - coords0\n",
    "            # print(\"flow:\")\n",
    "            # print(flow)\n",
    "            # print(flow.shape)\n",
    "            # print(\"------------------------------------------------\")\n",
    "            with autocast(enabled=self.args.mixed_precision):\n",
    "                net, up_mask, delta_flow = self.update_block(net, inp, corr, flow)\n",
    "\n",
    "            # F(t+1) = F(t) + \\Delta(t)\n",
    "            \n",
    "            coords1 = coords1 + delta_flow\n",
    "            # print(\"coords1:\")\n",
    "            # # print(coords1)\n",
    "            # print(coords1.shape)\n",
    "            # print(\"------------------------------------------------\")\n",
    "            \n",
    "            # upsample predictions\n",
    "            if up_mask is None:\n",
    "                flow_up = upflow8(coords1 - coords0)\n",
    "            else:\n",
    "                flow_up = self.upsample_flow(coords1 - coords0, up_mask)\n",
    "            # print(flow_up.shape)\n",
    "            flow_predictions.append(flow_up)\n",
    "\n",
    "        if test_mode:\n",
    "            return coords1 - coords0, flow_up\n",
    "\n",
    "        return flow_predictions, softCorrMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define args \n",
    "args = argparse.Namespace()\n",
    "model = nn.DataParallel(GMFlowNetModel(args), device_ids=[0])\n",
    "# model = GMFlowNetModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): GMFlowNetModel(\n",
      "    (fnet): Sequential(\n",
      "      (0): BasicConvEncoder(\n",
      "        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "        (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (1): POLAUpdate(\n",
      "        (blocks): ModuleList(\n",
      "          (0): POLATransBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): NeighborWindowAttention(\n",
      "              (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): POLATransBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): NeighborWindowAttention(\n",
      "              (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): POLATransBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): NeighborWindowAttention(\n",
      "              (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): POLATransBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): NeighborWindowAttention(\n",
      "              (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): POLATransBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): NeighborWindowAttention(\n",
      "              (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): POLATransBlock(\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): NeighborWindowAttention(\n",
      "              (Wq): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wk): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (Wv): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "              (act): GELU()\n",
      "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (cnet): BasicEncoder(\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (layer1): Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (norm3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (update_block): BasicUpdateBlock(\n",
      "      (encoder): BasicMotionEncoder(\n",
      "        (convc1): Conv2d(324, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (convf1): Conv2d(2, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "        (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (gru): SepConvGRU(\n",
      "        (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "        (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "        (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "        (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "        (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "        (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "      )\n",
      "      (flow_head): FlowHead(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (mask): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(256, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "# model.load_state_dict(torch.load(\"pretrained_models/new_model.pth\"), strict=True)\n",
    "model.load_state_dict(torch.load(\"checkpoints/checkpoints/gmflownet-carla-ClearNoon.pth\"), strict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0 0.0\n",
      "(320, 480, 2)\n"
     ]
    }
   ],
   "source": [
    "# test model on comeplete dataloader\n",
    "model.eval()\n",
    "for i_batch, data_blob in enumerate(valid_loader):\n",
    "    image1, image2, flow, valid = [x.cuda() for x in data_blob]\n",
    "    # print(image1)\n",
    "    # test model\n",
    "    pred = model(image1, image2)\n",
    "    cpu_input_image1 = image1[0].squeeze().cpu().numpy()\n",
    "    print(cpu_input_image1.max(), cpu_input_image1.min())\n",
    "    plt.figure()\n",
    "    plt.imshow(cpu_input_image1.transpose(1,2,0).astype(np.uint8))\n",
    "    plt.savefig(\"input2/random_crop_{}.png\".format(i_batch))\n",
    "    plt.close()\n",
    "    cpu_image = pred[0][-1].squeeze()\n",
    "    cpu_image = cpu_image.cpu().detach().numpy().transpose(1,2,0)\n",
    "    print(cpu_image.shape)\n",
    "    # visualize image using plt\n",
    "    # subplot\n",
    "    flow_cpu = flow.squeeze()\n",
    "    flow_cpu = flow_cpu.cpu().detach().numpy().transpose(1,2,0)\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(cpu_image[:,:,0])\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(flow_cpu[:,:,0])\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(np.abs(cpu_image[:,:,0] - flow_cpu[:,:,0]))\n",
    "    \n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(cpu_image[:,:,1])\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(flow_cpu[:,:,1])\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.imshow(np.abs(cpu_image[:,:,1] - flow_cpu[:,:,1]))\n",
    "    \n",
    "    plt.savefig(\"output2/figure_{}.png\".format(i_batch))\n",
    "    plt.close()\n",
    "    break\n",
    "    # if (i_batch+1)%10 == 0:\n",
    "    #     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmflownet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
=======
   "version": "3.8.13 (default, Oct 19 2022, 22:38:03) [MSC v.1916 64 bit (AMD64)]"
>>>>>>> b926d624c1591b89d602b5a00a66dd88aa5a7cc0
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ddde9d13d134af44646960e0f2d1aba00c99289dd0e638243d2648ee869cc94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
